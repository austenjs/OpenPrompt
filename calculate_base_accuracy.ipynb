{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize roberta-base\n",
    "from openprompt.plms import get_model_class\n",
    "model_class = get_model_class(plm_type = \"roberta-base\")\n",
    "model_path = 'roberta-base'\n",
    "config = model_class.config.from_pretrained(model_path)\n",
    "tokenizer = model_class.tokenizer.from_pretrained(model_path)\n",
    "model = model_class.model.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize prompt template\n",
    "from openprompt.prompts import ManualTemplate\n",
    "promptTemplate = ManualTemplate(\n",
    "    text = [\"<text_a>\", \"It\", \"was\", \"<mask>\"],\n",
    "    tokenizer = tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize verbalizer\n",
    "from openprompt.prompts import ManualVerbalizer\n",
    "classes = [\"negative\", \"positive\"]\n",
    "\n",
    "promptVerbalizer = ManualVerbalizer(\n",
    "    classes = classes,\n",
    "    label_words = {\n",
    "        \"negative\": [\"bad\"],\n",
    "        \"positive\": [\"great\"],\n",
    "    },\n",
    "    tokenizer = tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt model\n",
    "from openprompt import PromptForClassification\n",
    "promptModel = PromptForClassification(\n",
    "    template = promptTemplate,\n",
    "    model = model,\n",
    "    verbalizer = promptVerbalizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processor\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from openprompt.data_utils import InputExample\n",
    "from openprompt.data_utils.data_processor import DataProcessor\n",
    "\n",
    "class SST2Processor(DataProcessor):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.labels = [\"negative\", \"positive\"]\n",
    "\n",
    "    def get_examples(self, data_dir, split):\n",
    "        examples = []\n",
    "        path = os.path.join(data_dir, \"{}.tsv\".format(split))\n",
    "        df = pd.read_csv(path, sep='\\\\t', header = 0)\n",
    "        sentences = df['sentence']\n",
    "        labels = df['label']\n",
    "        for idx in range(len(sentences)):\n",
    "            sentence, label = sentences[idx], labels[idx]\n",
    "            example = InputExample(\n",
    "                guid = idx, text_a = sentence, label = int(label))\n",
    "            examples.append(example)\n",
    "                \n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auste\\anaconda3\\envs\\prompt-learning\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "path_to_train = './custom_data'\n",
    "dataset = SST2Processor().get_examples(path_to_train, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 10000it [00:06, 1453.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create Data Loader\n",
    "from openprompt import PromptDataLoader\n",
    "data_loader = PromptDataLoader(\n",
    "    dataset = dataset,\n",
    "    tokenizer = tokenizer,\n",
    "    template = promptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7368\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of train set\n",
    "import torch\n",
    "correctly_classified = 0\n",
    "samples = len(dataset)\n",
    "\n",
    "promptModel.eval()\n",
    "with torch.no_grad():\n",
    "    for data in data_loader:\n",
    "        logits = promptModel(data)\n",
    "        pred = torch.argmax(logits, dim = -1)\n",
    "        if pred == data[\"label\"]:\n",
    "            correctly_classified += 1\n",
    "\n",
    "print(f'Accuracy : {correctly_classified / samples}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a4ff1af5d6128ae1af0c267d9f4569bdb1b0b71b6acfc19a5b0c06f4de71adb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('prompt-learning': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
